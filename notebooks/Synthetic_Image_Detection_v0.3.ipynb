{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlAd5j3R-d5i"
      },
      "source": [
        "# Synthetic Image Detection\n",
        "---\n",
        "\n",
        "### Mk-0.3  :- Basic CNN (Multi-generator training)\n",
        "* GPU augmentation with kornia\n",
        "* Used CNN with...\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Data-preprocessing (GenImage -> BigGAN+VQDM dataset) :-\n",
        "\n",
        "*   Resizing all the images to 224x224 (std. for CNN based models). CNN expects fixed input shape. Avoids inconsistent pixel distributions.\n",
        "*   Resizing was done locally using python + cmd.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Requirments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (2.9.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (0.24.0)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (2.9.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.7)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: jupyter in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2025.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->-r requirements.txt (line 2)) (2.3.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->-r requirements.txt (line 2)) (12.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->-r requirements.txt (line 6)) (0.4.6)\n",
            "Requirement already satisfied: notebook in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter->-r requirements.txt (line 7)) (7.4.7)\n",
            "Requirement already satisfied: jupyter-console in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter->-r requirements.txt (line 7)) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter->-r requirements.txt (line 7)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter->-r requirements.txt (line 7)) (7.0.1)\n",
            "Requirement already satisfied: ipywidgets in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter->-r requirements.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: jupyterlab in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter->-r requirements.txt (line 7)) (4.4.9)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: comm>=0.1.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (0.2.3)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (1.8.17)\n",
            "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (9.6.0)\n",
            "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (5.9.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: psutil>=5.7 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (7.1.0)\n",
            "Requirement already satisfied: pyzmq>=25 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (27.1.0)\n",
            "Requirement already satisfied: tornado>=6.2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (6.5.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 7)) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 7)) (3.0.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 7)) (3.0.52)\n",
            "Requirement already satisfied: pygments in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 7)) (2.19.2)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 7)) (2.0.5)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 7)) (2.3.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 7)) (2.17.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 7)) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 7)) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 7)) (65.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (4.14.2)\n",
            "Requirement already satisfied: bleach[css]!=5.0.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: webencodings in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 7)) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 7)) (0.19.2)\n",
            "Requirement already satisfied: stack_data in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 7)) (0.6.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->-r requirements.txt (line 7)) (4.5.0)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (25.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.23.1)\n",
            "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.9.0)\n",
            "Requirement already satisfied: babel>=2.10 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (4.25.1)\n",
            "Requirement already satisfied: requests>=2.31 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (2.32.5)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter->-r requirements.txt (line 7)) (2.21.2)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.2.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 7)) (2.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (25.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 7)) (0.8.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.27.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (0.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 7)) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 7)) (0.2.3)\n",
            "Requirement already satisfied: fqdn in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: uri-template in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (24.11.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 7)) (2.23)\n",
            "Requirement already satisfied: lark>=1.2.2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: tzdata in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 7)) (2025.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kornia\n",
            "  Using cached kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "Collecting kornia_rs>=0.1.9\n",
            "  Using cached kornia_rs-0.1.9-cp311-cp311-win_amd64.whl (2.3 MB)\n",
            "Requirement already satisfied: packaging in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kornia) (25.0)\n",
            "Requirement already satisfied: torch>=1.9.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kornia) (2.9.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.9.1->kornia) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.9.1->kornia) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.9.1->kornia) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.9.1->kornia) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.9.1->kornia) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.9.1->kornia) (2025.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.9.1->kornia) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarth\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.9.1->kornia) (3.0.3)\n",
            "Installing collected packages: kornia_rs, kornia\n",
            "Successfully installed kornia-0.8.1 kornia_rs-0.1.9\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install kornia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from PIL import Image\n",
        "import kornia.augmentation as K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ensures Reproducibility (Phirse same results on every run)\n",
        "import random\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBDIRP_hAO2K"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBSXJKdJD5KB",
        "outputId": "e6aec868-2f0d-47a7-da23-b8f6e6dc3af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Directory: ['ai', 'nature']\n",
            "Test Directory: ['ai', 'nature']\n"
          ]
        }
      ],
      "source": [
        "# directories\n",
        "train_dir = rf\"C:\\Users\\sarth\\Dataset\\train\"\n",
        "test_dir = rf\"C:\\Users\\sarth\\Dataset\\val\"\n",
        "\n",
        "# Check contents of the folders\n",
        "print(\"Train Directory:\", os.listdir(train_dir))\n",
        "print(\"Test Directory:\", os.listdir(test_dir))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wvtqBK8GEQvm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 647996 | Val samples: 24000\n",
            "Classes: ['ai', 'nature']\n"
          ]
        }
      ],
      "source": [
        "# Basic transform to load images as tensors on CPU first\n",
        "train_base_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # just convert to tensor\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224))\n",
        "])\n",
        "\n",
        "# Datasets\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_base_transform)\n",
        "val_dataset = datasets.ImageFolder(root=test_dir, transform=val_transform)\n",
        "\n",
        "# Dataloaders (CPU only does basic loading)\n",
        "batch_size = 32\n",
        "num_workers = 2\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=False,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=1\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=False,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=1\n",
        ")\n",
        "\n",
        "# Define GPU augmentations using Kornia\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "gpu_train_augment = K.AugmentationSequential(\n",
        "    K.RandomCrop((224, 224), padding=8),\n",
        "    K.RandomHorizontalFlip(p=0.5),\n",
        "    K.RandomRotation(degrees=15.0),\n",
        "    K.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),\n",
        "    K.RandomGaussianBlur((3, 3), (0.1, 1.0)),\n",
        "    data_keys=[\"input\"]\n",
        ").to(device)\n",
        "\n",
        "# Normalization function (after GPU augmentation)\n",
        "mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
        "std = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
        "\n",
        "def normalize_batch(batch):\n",
        "    return (batch - mean) / std\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)}\")\n",
        "print(f\"Classes: {train_dataset.classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checking loaders & resource (GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking folder: C:\\Users\\sarth\\Dataset\\train\\ai\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ai: 100%|██████████| 323996/323996 [01:52<00:00, 2891.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking folder: C:\\Users\\sarth\\Dataset\\train\\nature\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nature: 100%|██████████| 324000/324000 [01:48<00:00, 2973.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking folder: C:\\Users\\sarth\\Dataset\\val\\ai\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ai: 100%|██████████| 12000/12000 [00:04<00:00, 2800.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking folder: C:\\Users\\sarth\\Dataset\\val\\nature\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nature: 100%|██████████| 12000/12000 [00:04<00:00, 2666.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Scan complete. 0 bad images found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Check for corrupted images in dataset folders\n",
        "FOLDERS = [\n",
        "    rf\"C:\\Users\\sarth\\Dataset\\train\\ai\",\n",
        "    rf\"C:\\Users\\sarth\\Dataset\\train\\nature\",\n",
        "    rf\"C:\\Users\\sarth\\Dataset\\val\\ai\",\n",
        "    rf\"C:\\Users\\sarth\\Dataset\\val\\nature\"\n",
        "]\n",
        "\n",
        "bad_files = []\n",
        "\n",
        "for folder in FOLDERS:\n",
        "    print(f\"Checking folder: {folder}\")\n",
        "    files = [\n",
        "        f for f in os.listdir(folder)\n",
        "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\"))\n",
        "    ]\n",
        "    for f in tqdm(files, desc=os.path.basename(folder)):\n",
        "        path = os.path.join(folder, f)\n",
        "        try:\n",
        "            with Image.open(path) as img:\n",
        "                img.verify()  # Checks for corruption\n",
        "        except Exception as e:\n",
        "            bad_files.append((path, str(e)))\n",
        "\n",
        "print(f\"\\nScan complete. {len(bad_files)} bad images found.\")\n",
        "if bad_files:\n",
        "    print(\"Examples:\")\n",
        "    for bf in bad_files[:10]:\n",
        "        print(\"  \", bf[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKIw6jW7Kn7c"
      },
      "source": [
        "### Defining basic CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nPScCyZhKnfF"
      },
      "outputs": [],
      "source": [
        "# SImpleCNN upgraded with explicit Grad-CAM layer and regularization\n",
        "class SimpleCNN_v2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN_v2, self).__init__()\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32), # stabilizes gradients\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Explicit Grad-CAM layer\n",
        "        self.last_conv = nn.Conv2d(64, 256, 3, padding=1)\n",
        "        self.bn_last   = nn.BatchNorm2d(256)\n",
        "        self.relu_last = nn.ReLU()\n",
        "        self.pool_last = nn.MaxPool2d(2)\n",
        "\n",
        "        # Global average pooling and classifier\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1) # Reduces Overfitting and enables Grad-CAM (Regularization)\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.ReLU(),           # Adds non-linearity before FC layers\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),     # Regularization (Reduces overfitting)\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.last_conv(x)\n",
        "        x = self.bn_last(x)\n",
        "        x = self.relu_last(x)\n",
        "        x = self.pool_last(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate model\n",
        "model = SimpleCNN_v2()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5kjnQ5ow13I"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYAg3YDHwmDe",
        "outputId": "3cc71ac1-7c5b-472b-c7d2-7fd295d25df1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sarth\\AppData\\Local\\Temp\\ipykernel_25156\\2739816746.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resuming from last checkpoint...\n",
            "Resumed from epoch 1 with best accuracy 0.8860\n",
            "Epoch 2/10: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  52%|█████▏    | 10625/20250 [48:17<43:44,  3.67batch/s, loss=0.457]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m scaler.scale(loss).backward()\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)    # Gradients stable is not needed as we stabalised it with BatchNorm and Mixed Precision\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m scaler.update()\n\u001b[32m     63\u001b[39m running_loss += loss.detach().item()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\sarthak\\RCOEM\\3rd\\Projects\\ML\\Synthetic Media detection\\cuda-venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\sarthak\\RCOEM\\3rd\\Projects\\ML\\Synthetic Media detection\\cuda-venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\sarthak\\RCOEM\\3rd\\Projects\\ML\\Synthetic Media detection\\cuda-venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Setup for training with checkpointing\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN_v2().to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()      # More stable than BCELoss with raw outputs (stable binary classification)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)  # L2 Regularization\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.7) # reduces LR only if validation accuracy plateaus\n",
        "scaler = torch.amp.GradScaler(\"cuda\") # for safe scaling during backprop\n",
        "\n",
        "# Maintaing history for analysis\n",
        "history = {\"train_loss\": [], \"val_acc\": [], \"val_loss\": [], \"lr\": []}\n",
        "\n",
        "# Directory for saving checkpoints\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"last_checkpoint.pth\")\n",
        "\n",
        "start_epoch = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "# Load checkpoint if resuming\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"Resuming from last checkpoint...\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"model_state\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
        "    scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
        "    scaler.load_state_dict(checkpoint[\"scaler_state\"])\n",
        "    start_epoch = checkpoint[\"epoch\"] + 1\n",
        "    best_acc = checkpoint.get(\"best_acc\", 0.0)\n",
        "    print(f\"Resumed from epoch {start_epoch} with best accuracy {best_acc:.4f}\")\n",
        "\n",
        "patience = 3  # for early stopping: stop after 3 epochs with no improvement\n",
        "patience_counter = 0\n",
        "epochs = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: \")\n",
        "\n",
        "    with tqdm(train_loader, desc=\"Training\", unit=\"batch\") as tepoch:\n",
        "        for images, labels in tepoch:\n",
        "            images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "            images = gpu_train_augment(images)\n",
        "            images = normalize_batch(images)\n",
        "\n",
        "            optimizer.zero_grad()               # clear gradients for next batch\n",
        "            with torch.amp.autocast(\"cuda\"):    # Mixed precision forward\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward pass\n",
        "            scaler.scale(loss).backward()\n",
        "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)    # Gradients stable is not needed as we stabalised it with BatchNorm and Mixed Precision\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.detach().item()\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct, total, val_loss = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            images = normalize_batch(images)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss_val = criterion(outputs, labels.unsqueeze(1).float())\n",
        "            val_loss += loss_val.item()\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            correct += (preds == labels.unsqueeze(1)).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_acc = correct / total\n",
        "    val_loss /= len(val_loader)\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    scheduler.step(val_loss) # step based on validation loss\n",
        "\n",
        "    if (epoch + 1) % 2 == 0 and device.type == \"cuda\":\n",
        "        print(\"Clearing unused CUDA memory to avoid fragmentation...\")\n",
        "        torch.cuda.empty_cache()        # clear unused memory every 2 epochs to avoid fragmentation\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr'] # get current learning rate\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {avg_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}\")\n",
        "\n",
        "    history[\"train_loss\"].append(avg_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"lr\"].append(current_lr)\n",
        "\n",
        "\n",
        "    # Proactive early stopping based on validation accuracy\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        patience_counter = 0  # reset counter\n",
        "        best_checkpoint = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"scheduler_state\": scheduler.state_dict(),\n",
        "            \"scaler_state\": scaler.state_dict(),\n",
        "            \"best_acc\": best_acc\n",
        "        }\n",
        "        torch.save(best_checkpoint, os.path.join(checkpoint_dir, \"best_checkpoint.pth\"))\n",
        "        print(f\"Best model updated! New Val Acc: {best_acc:.4f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"No improvement for {patience_counter}/{patience} epochs.\")\n",
        "\n",
        "    # Initiate early stop\n",
        "    if patience_counter >= patience:\n",
        "        print(\"\\nEarly stopping initiated: no improvement for 3 epochs.\")\n",
        "        torch.save(best_checkpoint, os.path.join(checkpoint_dir, \"final_best_model.pth\"))\n",
        "        print(\"Final best model saved before stopping.\")\n",
        "        break\n",
        "\n",
        "\n",
        "    # Save checkpoints\n",
        "    checkpoint = {\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scheduler_state\": scheduler.state_dict(),\n",
        "        \"scaler_state\": scaler.state_dict(),\n",
        "        \"best_acc\": best_acc\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
        "    print(\"Initiating next epoch in 20 seconds...\")\n",
        "    time.sleep(20)  # CPU cooldown before next epoch\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nTraining complete 🔥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache() # Clears VRAM memory cache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load best model for evaluation\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "checkpoint = torch.load(os.path.join(checkpoint_dir, \"best_checkpoint.pth\"), map_location=device)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Validation Accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "all_preds, all_labels = [], []\n",
        "\n",
        "model.eval()  # Make sure model is in evaluation mode\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = (outputs > 0.5).float()\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=[\"Real\", \"Fake\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix - Final Model\")\n",
        "plt.show()\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Final validation accuracy\n",
        "val_acc = (all_preds == all_labels).mean()\n",
        "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score: 0.6658\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.60      0.98      0.75     12000\n",
            "        Fake       0.96      0.35      0.51     12000\n",
            "\n",
            "    accuracy                           0.67     24000\n",
            "   macro avg       0.78      0.67      0.63     24000\n",
            "weighted avg       0.78      0.67      0.63     24000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# r2 score\n",
        "r2 = roc_auc_score(all_labels, all_preds)\n",
        "print(f\"ROC AUC Score: {r2:.4f}\")\n",
        "\n",
        "# classification report\n",
        "report = classification_report(all_labels, all_preds, target_names=[\"Real\", \"Fake\"])\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.5111, Val acc: 0.7267\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ai       0.65      0.97      0.78     12000\n",
            "      nature       0.94      0.49      0.64     12000\n",
            "\n",
            "    accuracy                           0.73     24000\n",
            "   macro avg       0.79      0.73      0.71     24000\n",
            "weighted avg       0.79      0.73      0.71     24000\n",
            "\n",
            "ROC AUC: 0.9202571701388889\n"
          ]
        }
      ],
      "source": [
        "# Detailed evaluation with probabilities\n",
        "\n",
        "model.eval()\n",
        "all_probs, all_preds, all_labels = [], [], []\n",
        "val_loss = 0.0\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item() * images.size(0)\n",
        "        probs = torch.sigmoid(outputs).cpu().numpy().ravel()\n",
        "        preds = (probs > 0.5).astype(int)\n",
        "        all_probs.extend(probs.tolist())\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(labels.cpu().numpy().ravel().astype(int).tolist())\n",
        "\n",
        "val_loss = val_loss / len(val_dataset)\n",
        "print(f\"Val loss: {val_loss:.4f}, Val acc: {np.mean(np.array(all_preds)==np.array(all_labels)):.4f}\")\n",
        "\n",
        "# Classification report + AUC\n",
        "print(classification_report(all_labels, all_preds, target_names=train_dataset.classes))\n",
        "try:\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    print(\"ROC AUC:\", auc)\n",
        "except Exception as e:\n",
        "    print(\"ROC AUC could not be computed:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing on VQDM val dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VQDM_test_dir = rf'D:\\sarthak\\RCOEM\\3rd\\Projects\\ML\\Synthetic Media detection\\Datasets\\VQDM\\imagenet_ai_0419_vqdm\\imagenet_ai_0419_vqdm\\val'\n",
        "VQDM_val_dataset = datasets.ImageFolder(root=VQDM_test_dir, transform=val_transform)\n",
        "VQDM_val_loader = DataLoader(VQDM_val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in VQDM_val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct += (preds == labels.unsqueeze(1)).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "val_acc = correct / total\n",
        "scheduler.step(val_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(val_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_preds_VQDM, all_labels_VQDM = [], []\n",
        "\n",
        "model.eval()  # Make sure model is in evaluation mode\n",
        "with torch.no_grad():\n",
        "    for images, labels in VQDM_val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = (outputs > 0.5).float()\n",
        "        all_preds_VQDM.extend(preds.cpu().numpy())\n",
        "        all_labels_VQDM.extend(labels.cpu().numpy())\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels_VQDM, all_preds_VQDM)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=[\"Real\", \"Fake\"])\n",
        "disp.plot(cmap=plt.cm.Reds)\n",
        "plt.title(\"Confusion Matrix - VQDM val dataset\")\n",
        "plt.show()\n",
        "\n",
        "all_preds_VQDM = np.array(all_preds_VQDM)\n",
        "all_labels_VQDM = np.array(all_labels_VQDM)\n",
        "\n",
        "# Final validation accuracy\n",
        "val_acc = (all_preds_VQDM == all_labels_VQDM).mean()\n",
        "print(f\"Final VQDM Validation Accuracy: {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_images(model, image_paths, transform, device):\n",
        "    \"\"\"\n",
        "    Display predictions for multiple input images with confidence scores.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model.\n",
        "        image_paths: List of image file paths.\n",
        "        transform: Transform pipeline (e.g., val_transform).\n",
        "        device: 'cuda' or 'cpu'.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    for i, img_path in enumerate(image_paths):\n",
        "        try:\n",
        "            # Load and preprocess image\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            img_t = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "            # Predict\n",
        "            with torch.no_grad():\n",
        "                output = model(img_t)\n",
        "                prob = torch.sigmoid(output).item()\n",
        "\n",
        "            # Classification decision\n",
        "            label = \"Fake (AI-generated)\" if prob > 0.5 else \"Real (original)\"\n",
        "            conf = prob if prob > 0.5 else 1 - prob\n",
        "\n",
        "            # Plotting\n",
        "            plt.subplot(2, (len(image_paths) + 1) // 2, i + 1)\n",
        "            plt.imshow(np.array(img))\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(f\"{label}\\nConf: {conf:.3f}\", fontsize=10)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_paths = []\n",
        "\n",
        "evaluate_images(model, image_paths, val_transform, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python(cuda-venv)",
      "language": "python",
      "name": "cuda-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
